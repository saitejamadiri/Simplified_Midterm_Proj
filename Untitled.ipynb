{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc3ceca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "joblib\n",
    "scipy\n",
    "numpy\n",
    "scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "674a3699",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p opt/ml/model  \n",
    "!cp model.pkl opt/ml/model/model.pkl\n",
    "!cp tfidf_vectorizer.pkl opt/ml/model/tfidf_vectorizer.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37ce8253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pickle\n",
    "import boto3\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.pkl\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "input_fn\n",
    "    request_body: The body of the request sent to the model.\n",
    "    request_content_type: (string) specifies the format/variable type of the request\n",
    "\"\"\"\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == 'application/json':\n",
    "        input_data = json.loads(request_body)\n",
    "        return input_data\n",
    "    else:\n",
    "        raise ValueError(\"This model only supports application/json input\")\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned data from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    # Process the input data if necessary\n",
    "    processed_data = process_input(input_data, model)\n",
    "    # Make predictions using the model\n",
    "    predictions = model.predict(processed_data)\n",
    "    return predictions\n",
    "\n",
    "def process_input(input_data, model):\n",
    "    # Process input data as needed before passing to the model for prediction\n",
    "    X = input_data['url']\n",
    "    vectorizer = joblib.load(os.path.join(\"opt/ml/model\", \"tfidf_vectorizer.pkl\"))\n",
    "    X_vect = vectorizer.transform(X)\n",
    "    return X_vect\n",
    "\n",
    "\"\"\"\n",
    "output_fn\n",
    "    prediction: the returned value from predict_fn above\n",
    "    content_type: the content type the endpoint expects to be returned. Ex: JSON, string\n",
    "\"\"\"\n",
    "def output_fn(prediction, content_type):\n",
    "    prediction_str = prediction[0]\n",
    "    response = {\"type\": prediction_str}\n",
    "    return json.dumps(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "088251e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.pkl\n",
      "inference.py\n",
      "tfidf_vectorizer.pkl\n",
      "requirements.txt\n",
      "opt/\n",
      "opt/ml/\n",
      "opt/ml/model/\n",
      "opt/ml/model/model.pkl\n",
      "opt/ml/model/tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "!tar -cvpzf model.tar.gz model.pkl inference.py tfidf_vectorizer.pkl requirements.txt opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1016145c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.2.1 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.2.1 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['phishing']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.2.1 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pickle\n",
    "import boto3\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.pkl\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "input_fn\n",
    "    request_body: The body of the request sent to the model.\n",
    "    request_content_type: (string) specifies the format/variable type of the request\n",
    "\"\"\"\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == 'application/json':\n",
    "        input_data = json.loads(request_body)\n",
    "        return input_data\n",
    "    else:\n",
    "        raise ValueError(\"This model only supports application/json input\")\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned data from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    # Process the input data if necessary\n",
    "    processed_data = process_input(input_data, model)\n",
    "    # Make predictions using the model\n",
    "    predictions = model.predict(processed_data)\n",
    "    return predictions\n",
    "\n",
    "def process_input(input_data, model):\n",
    "    # Process input data as needed before passing to the model for prediction\n",
    "    X = input_data['url']\n",
    "    vectorizer = joblib.load(os.path.join(\"opt/ml/model\", \"tfidf_vectorizer.pkl\"))\n",
    "    X_vect = vectorizer.transform(X)\n",
    "    return X_vect\n",
    "\n",
    "\"\"\"\n",
    "output_fn\n",
    "    prediction: the returned value from predict_fn above\n",
    "    content_type: the content type the endpoint expects to be returned. Ex: JSON, string\n",
    "\"\"\"\n",
    "def output_fn(prediction, content_type):\n",
    "    # Convert prediction to string\n",
    "    prediction_str = prediction[0]\n",
    "    response = {\"type\": prediction_str}\n",
    "    return json.dumps(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = model_fn(\"\")  # Load the model\n",
    "    prediction = predict_fn({'url': [\"http://malicious-site.com\"]}, model)\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6da8d26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "import tarfile\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43915820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "#Setup\n",
    "client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "boto_session = boto3.session.Session()\n",
    "s3 = boto_session.resource('s3')\n",
    "region = boto_session.region_name\n",
    "print(region)\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = \"arn:aws:iam::992382531741:role/LabRole\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc9c2262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve sklearn image\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"sklearn\",\n",
    "    region=region,\n",
    "    version=\"1.2-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.t2.medium\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5c18c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-992382531741\n"
     ]
    }
   ],
   "source": [
    "#Bucket for model artifacts\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "print(default_bucket)\n",
    "\n",
    "#Upload tar.gz to bucket\n",
    "model_artifacts = f\"s3://{default_bucket}/model.tar.gz\"\n",
    "response = s3.meta.client.upload_file('model.tar.gz', default_bucket, 'model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4648417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: sklearn-test2024-05-05-05-25-40\n",
      "Model Arn: arn:aws:sagemaker:us-east-1:992382531741:model/sklearn-test2024-05-05-05-25-40\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Model Creation\n",
    "model_name = \"sklearn-test\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Model name: \" + model_name)\n",
    "create_model_response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            \"Image\": image_uri,\n",
    "            \"Mode\": \"SingleModel\",\n",
    "            \"ModelDataUrl\": model_artifacts,\n",
    "            \"Environment\": {'SAGEMAKER_SUBMIT_DIRECTORY': model_artifacts,\n",
    "                           'SAGEMAKER_PROGRAM': 'inference.py'} \n",
    "        }\n",
    "    ],\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57fcab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Configuration Arn: arn:aws:sagemaker:us-east-1:992382531741:endpoint-config/sklearn-epc2024-05-05-05-31-17\n"
     ]
    }
   ],
   "source": [
    "#Step 2: EPC Creation\n",
    "sklearn_epc_name = \"sklearn-epc\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName=sklearn_epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"sklearnvariant\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.t2.medium\",\n",
    "            \"InitialInstanceCount\": 1\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36df940b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:992382531741:endpoint/sklearn-local-ep2024-05-05-05-31-48\n"
     ]
    }
   ],
   "source": [
    "#Step 3: EP Creation\n",
    "endpoint_name = \"sklearn-local-ep\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=sklearn_epc_name,\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b21c4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "InService\n",
      "{'EndpointName': 'sklearn-local-ep2024-05-05-05-31-48', 'EndpointArn': 'arn:aws:sagemaker:us-east-1:992382531741:endpoint/sklearn-local-ep2024-05-05-05-31-48', 'EndpointConfigName': 'sklearn-epc2024-05-05-05-31-17', 'ProductionVariants': [{'VariantName': 'sklearnvariant', 'DeployedImages': [{'SpecifiedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3', 'ResolvedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn@sha256:20bb6714740d1b80a6b39b6ae06b928c59b40b394b083f72435b87e59dda0364', 'ResolutionTime': datetime.datetime(2024, 5, 5, 5, 31, 49, 781000, tzinfo=tzlocal())}], 'CurrentWeight': 1.0, 'DesiredWeight': 1.0, 'CurrentInstanceCount': 1, 'DesiredInstanceCount': 1}], 'EndpointStatus': 'InService', 'CreationTime': datetime.datetime(2024, 5, 5, 5, 31, 49, 54000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 5, 5, 5, 37, 21, 525000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '224ac476-9608-4629-aba1-156b50443be1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '224ac476-9608-4629-aba1-156b50443be1', 'content-type': 'application/x-amz-json-1.1', 'content-length': '767', 'date': 'Sun, 05 May 2024 05:37:21 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "#Monitor creation\n",
    "describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(15)\n",
    "print(describe_endpoint_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "376809cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'defacement'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "# Initialize the SageMaker runtime client\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "# Define your input data\n",
    "\"\"\"vanderbilt.rivals.com/viewcoach.asp?coach=2079&sport=1&year=2011\tbenign\n",
    "http://peluqueriadeautor.com/index.php?option=com_virtuemart&page=shop.browse&category_id=31&Itemid=70\tdefacement\n",
    "movies.yahoo.com/shop?d=hv&cf=info&id=1800340831\tbenign\n",
    "cyndislist.com/us/pa/counties\tbenign\n",
    "http://www.824555.com/app/member/SportOption.php?uid=guest&langx=gb\tmalware\n",
    "http://www.raci.it/component/user/reset.html\tdefacement\n",
    "https://docs.google.com/spreadsheet/viewform?formkey=dGg2Z1lCUHlSdjllTVNRUW50TFIzSkE6MQ\tphishing\n",
    "psychology.wikia.com/wiki/Phonemes\tbenign\n",
    "\"\"\"\n",
    "input_data = {\n",
    "    'url': [\"http://peluqueriadeautor.com/index.php?option=com_virtuemart&page=shop.browse&category_id=31&Itemid=70\"]\n",
    "}\n",
    "\n",
    "# Convert input data to JSON string\n",
    "payload = json.dumps(input_data)\n",
    "\n",
    "# Specify the endpoint name\n",
    "endpoint_name = 'sklearn-local-ep2024-05-05-05-31-48'\n",
    "\n",
    "# Call the endpoint\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType='application/json',\n",
    "                                   Body=payload)\n",
    "\n",
    "# Decode and print the response\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613b322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
